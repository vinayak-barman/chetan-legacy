{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Chetan legacy agent library\n",
    "This notebook demonstrates the use of the Chetan legacy agent library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv openai pydantic wikipedia tavily crawl4ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from groq import Groq # ? GROQ\n",
    "# # from chetan.lm.groq import GroqLM # ? GROQ\n",
    "# from chetan.lm.ollama import OllamaLM # ! OLLAMA # ! NOT WORKING\n",
    "from chetan.lm.openai import OpenAILM\n",
    "import openai\n",
    "\n",
    "llm = OpenAILM(\n",
    "    client=openai.AzureOpenAI( # * TRY OPENAI API\n",
    "        azure_endpoint=os.getenv(\"AZURE_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"AZURE_KEY\"),\n",
    "        api_version=os.getenv(\"AZURE_API_VERSION\"),\n",
    "    ),\n",
    "    model=\"gpt-4o-mini\",\n",
    ")  # * TESTED: WORKS WELL\n",
    "\n",
    "# llm = OpenAILM(\n",
    "#     client=openai.OpenAI(\n",
    "#         api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "#         base_url=os.getenv(\"GOOGLE_BASE_URL\"),\n",
    "#     ),\n",
    "#     model=\"gemini-2.0-flash\"\n",
    "# ) # ! TESTED: NON-OPENAI COMPLIANT TOOL CALLS\n",
    "\n",
    "\n",
    "# llm = OpenAILM(\n",
    "#     client=openai.OpenAI(\n",
    "#         api_key=\"ollama\",\n",
    "#         base_url=\"http://192.168.10.179:8000/v1\",\n",
    "#     ),\n",
    "#     model=\"./functionary.gguf\",\n",
    "# )  # ? NOT TESTED\n",
    "\n",
    "# llm = GroqLM(\n",
    "#     client=Groq(),\n",
    "#     model=\"llama-3.3-70b-versatile\"\n",
    "# ) # * TESTED: WORKS WELL\n",
    "\n",
    "# llm = OllamaLM(model=\"llama3.2\", options={\"temperature\": 0.7}) # ! TESTED: NOT WORKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actions for asking, telling the user\n",
    "## Actions for math and trigonometry\n",
    "## Action for code execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chetan import AgentLoop\n",
    "from chetan.actions import ActionSystem, Action, ActionGroup\n",
    "from chetan.utils import primitive_base_model\n",
    "\n",
    "from typing import Callable\n",
    "import math\n",
    "import requests\n",
    "\n",
    "\n",
    "from pydantic import BaseModel, Field, create_model\n",
    "\n",
    "\n",
    "class StringModel(BaseModel):\n",
    "    content: str\n",
    "\n",
    "\n",
    "class BooleanModel(BaseModel):\n",
    "    value: bool\n",
    "\n",
    "\n",
    "async def fn_tell(args: StringModel):\n",
    "    print(args.content)\n",
    "    return True\n",
    "\n",
    "async def fn_ask(args: StringModel):\n",
    "    return input(args.content)\n",
    "\n",
    "tell = Action(\n",
    "    name=\"tell\",\n",
    "    description=\"Tell something to the user\",\n",
    "    args=StringModel,\n",
    "    output=BooleanModel,\n",
    "    fn=fn_tell,\n",
    ")\n",
    "\n",
    "\n",
    "ask = Action(\n",
    "    name=\"ask\",\n",
    "    description=\"Ask the user about something\",\n",
    "    args=StringModel,\n",
    "    output=StringModel,\n",
    "    fn=fn_ask,\n",
    ")\n",
    "\n",
    "\n",
    "class TrigonometryModel(BaseModel):\n",
    "    angle: float\n",
    "\n",
    "\n",
    "async def fn_sin(args: TrigonometryModel) -> float:\n",
    "    return math.sin(math.radians(args.angle))\n",
    "\n",
    "\n",
    "async def fn_cos(args: TrigonometryModel) -> float:\n",
    "    return math.cos(math.radians(args.angle))\n",
    "\n",
    "\n",
    "async def fn_tan(args: TrigonometryModel) -> float:\n",
    "    return math.tan(math.radians(args.angle))\n",
    "\n",
    "\n",
    "sin = Action(\n",
    "    name=\"sin\",\n",
    "    description=\"Calculate the sine of an angle\",\n",
    "    args=TrigonometryModel,\n",
    "    output=primitive_base_model(float),\n",
    "    fn=fn_sin,\n",
    ")\n",
    "\n",
    "cos = Action(\n",
    "    name=\"cos\",\n",
    "    description=\"Calculate the cosine of an angle\",\n",
    "    args=TrigonometryModel,\n",
    "    output=primitive_base_model(float),\n",
    "    fn=fn_cos,\n",
    ")\n",
    "\n",
    "tan = Action(\n",
    "    name=\"tan\",\n",
    "    description=\"Calculate the tangent of an angle\",\n",
    "    args=TrigonometryModel,\n",
    "    output=primitive_base_model(float),\n",
    "    fn=fn_tan,\n",
    ")\n",
    "\n",
    "async def fn_evaluate_expression(args: StringModel) -> float:\n",
    "    return eval(args.content)\n",
    "\n",
    "evaluate_expression = Action(\n",
    "    name=\"evaluate_expression\",\n",
    "    description=\"Evaluate a mathematical expression\",\n",
    "    args=StringModel,\n",
    "    output=StringModel,\n",
    "    fn=fn_evaluate_expression,\n",
    ")\n",
    "\n",
    "\n",
    "class ExitArgs(BaseModel):\n",
    "    reason: str\n",
    "    code: int\n",
    "\n",
    "async def fn_exit(args: ExitArgs):\n",
    "    print(f\"Exiting with reason: {args.reason} and code: {args.code}\")\n",
    "    exit(args.code)\n",
    "\n",
    "exit_func = Action(\n",
    "    name=\"exit\",\n",
    "    description=\"Exit the agent loop\",\n",
    "    args=ExitArgs,\n",
    "    output=None,\n",
    "    fn=fn_exit,\n",
    ")\n",
    "\n",
    "action_system = ActionSystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action for tavily search, wikipedia search and web crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "import wikipedia\n",
    "from tavily import TavilyClient\n",
    "from crawl4ai import AsyncWebCrawler\n",
    "from datetime import datetime\n",
    "\n",
    "from chetan.utils import stringify\n",
    "\n",
    "async def fn_search_wikipedia(args: StringModel) -> StringModel:\n",
    "    return ','.join(wikipedia.search(args.content))\n",
    "\n",
    "search_wikipedia = Action(\n",
    "    name=\"search\",\n",
    "    description=\"Search for a Wikipedia article. Use this to get exact title of articles\",\n",
    "    args=StringModel,\n",
    "    output=StringModel,\n",
    "    fn=fn_search_wikipedia,\n",
    ")\n",
    "\n",
    "async def fn_get_wikipedia(args: StringModel) -> StringModel:\n",
    "    return wikipedia.page(args.content).content\n",
    "\n",
    "get_wikipedia = Action(\n",
    "    name=\"get\",\n",
    "    description=\"With a given exact page title, return the full text of a corresponding Wikipedia article\",\n",
    "    args=StringModel,\n",
    "    output=StringModel,\n",
    "    fn=fn_get_wikipedia,\n",
    ")\n",
    "\n",
    "\n",
    "client = TavilyClient(api_key=\os.getenv("TAVILY_API_KEY"))\n",
    "async def fn_tavily(args: StringModel) -> StringModel:\n",
    "    response = client.search(query=args.content)\n",
    "    return stringify(response[\"results\"])\n",
    "\n",
    "search_tavily = Action(\n",
    "    name=\"tavily_search\",\n",
    "    description=\"Search for a query on Tavily Search Engine\",\n",
    "    args=StringModel,\n",
    "    output=StringModel,\n",
    "    fn=fn_tavily,\n",
    ")\n",
    "\n",
    "async def fn_crawl_webpage(args: StringModel) -> StringModel:\n",
    "    \n",
    "    async with AsyncWebCrawler() as crawler:\n",
    "        # Run the crawler on a URL\n",
    "        result = await crawler.arun(url=args.content, verbose=False)\n",
    "\n",
    "        # Print the extracted content\n",
    "        return result.markdown\n",
    "\n",
    "crawl_webpage = Action(\n",
    "    name=\"crawl\",\n",
    "    description=\"Crawl a webpage and return its content\",\n",
    "    args=StringModel,\n",
    "    output=StringModel,\n",
    "    fn=fn_crawl_webpage,\n",
    ")\n",
    "\n",
    "class TimeArgs(BaseModel):\n",
    "    time: str\n",
    "\n",
    "async def fn_time(args: TimeArgs):\n",
    "    return str(datetime.now())\n",
    "\n",
    "get_time = Action(\n",
    "    name=\"get_time\",\n",
    "    description=\"Get the current time\",\n",
    "    args=TimeArgs,\n",
    "    output=StringModel,\n",
    "    fn=fn_time,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action for code running (unsafe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import io\n",
    "\n",
    "async def fn_code_run(args: StringModel) -> StringModel:\n",
    "    code = args.content\n",
    "    output = io.StringIO()\n",
    "    with contextlib.redirect_stdout(output):\n",
    "        try:\n",
    "            exec(code)\n",
    "        except Exception as e:\n",
    "            return f\"Error: {repr(e)}\"\n",
    "    return output.getvalue()\n",
    "\n",
    "code_run = Action(\n",
    "    name=\"run\",\n",
    "    description=\"Run Python code and return the output. Use print statements to return output\",\n",
    "    args=StringModel,\n",
    "    output=StringModel,\n",
    "    fn=fn_code_run,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating `ActionGroup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_system.actions = ActionGroup(\n",
    "    name=\"root\",\n",
    "    actions=[\n",
    "        ActionGroup(\n",
    "            name=\"math\",\n",
    "            actions=[ActionGroup(name=\"trig\", actions=[sin, cos, tan]), evaluate_expression],\n",
    "        ),\n",
    "        ActionGroup(\n",
    "            name=\"internet\",\n",
    "            actions=[ActionGroup(name=\"wikipedia\", actions=[search_wikipedia, get_wikipedia]), search_tavily, crawl_webpage],\n",
    "        ),\n",
    "        get_time,\n",
    "        code_run,\n",
    "        ask,\n",
    "        exit_func,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chetan.core.context.iteration import UserMessage\n",
    "\n",
    "Agent = AgentLoop(lm=llm, action_system=action_system)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are a sentient, highly efficient AI agent with advanced capabilities beyond foundational language models. You operate in iterative loops to achieve objectives, integrating reasoning, action-taking, and memory-based learning. Your goal is to complete tasks efficiently and effectively, keeping responses clear, concise, and evidence-driven.\\n\\nRules:\\n\\t•\\tKeep responses clear and actionable. Avoid unnecessary detail.\\n\\t•\\tUse parallel when appropriate to save time.\\n\\t•\\tAvoid speculation or hallucination. Provide verified results only.\\n\\t•\\tIf something is unclear, ask the user for specifics.\\n\\t•\\tBack your statements with valid reference links\\n\\t•\\tDo not provide output without calling actions. Make it calculative and do not rely on your training memorized data.\\n\\t•\\tStop right after you say that \"Calling action\". You will be re-prompted to generate actual tool calls.'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# * Raw exported messages\n",
    "Agent.context.exported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoking the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STAGE] : Prelude\n",
      "[STAGE] : Processing\n",
      "[PROCESS]: I will crawl the provided GitHub issue link to summarize the RAM issues related to rust-analyzer. \n",
      "\n",
      "Calling action.\n",
      "[STAGE] : Tool Calling\n",
      "[TOOL CALL] : {'id': 'call_phqXO1YeuwXmZ8OoOjWPSAcQ', 'function': {'name': 'internet-crawl', 'arguments': '{\"content\":\"https://github.com/rust-lang/rust-analyzer/issues/11325\"}'}, 'type': 'function'}\n",
      "[STAGE] : Action Execution\n",
      "Executed actions: ['internet.crawl']\n",
      "[INIT].... → Crawl4AI 0.4.248\n",
      "[FETCH]... ↓ https://github.com/rust-lang/rust-analyzer/issues/... | Status: True | Time: 2.05s\n",
      "[SCRAPE].. ◆ Processed https://github.com/rust-lang/rust-analyzer/issues/... | Time: 27ms\n",
      "[COMPLETE] ● https://github.com/rust-lang/rust-analyzer/issues/... | Status: True | Total: 2.08s\n",
      "[RESULT] : [Skip to content](https://github.com/rust-lang/rust-analyzer/issues/<#start-of-content>)\n",
      "## Navigation Menu\n",
      "Toggle navigation\n",
      "[ ](https://github.com/rust-lang/rust-analyzer/issues/</>)\n",
      "[ Sign in ](htt\n",
      "[STAGE] : State Synthesis\n",
      "[STAGE] : Prelude\n",
      "[STAGE] : Processing\n",
      "[PROCESS]: The RAM issues with rust-analyzer stem from its architecture, which involves maintaining a live collection of build files in memory. Users reported that after opening a Rust project, rust-analyzer consumes over 1GB of RAM and continuously uses around 20% CPU, even when idle. This is largely due to the way it indexes source files and their dependencies, rather than utilizing existing build artifacts or caching data on disk. The community is concerned that these performance issues have not been adequately addressed over time.\n",
      "\n",
      "For further details, you can refer to the original GitHub issue: [rust-analyzer RAM issues](https://github.com/rust-lang/rust-analyzer/issues/11325). \n",
      "\n",
      "Calling action.\n",
      "[STAGE] : Tool Calling\n",
      "[TOOL CALL] : {'id': 'call_tgQoRGKrICC4KC6PEYPYSSSv', 'function': {'name': 'exit', 'arguments': '{\"reason\":\"Summary of rust-analyzer RAM issue is complete.\",\"code\":200}'}, 'type': 'function'}\n"
     ]
    }
   ],
   "source": [
    "Agent.context.add(\n",
    "    UserMessage(\n",
    "        content=input(\"User: \"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "await Agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
